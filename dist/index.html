<!DOCTYPE html PUBLIC>
        <html lang="en">
        <head>
            <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
            <meta content="width=device-width, initial-scale=1" name="viewport">
            <title>blob</title>
            <meta name="description" content="Example of a book design with paged.js" />
            <meta name="copyright" content="MIT License (MIT)" />
            <meta name="DC.Date.created" scheme="W3CDTF" content="2018-03-18" />
            <script src="js/paged.polyfill.js"></script>
            <link href="css/book.css" rel="stylesheet" type="text/css">
            <link href="fonts/permian/stylesheet.css" rel="stylesheet" type="text/css">
            <link href="fonts/HKGrotesk/stylesheet.css" rel="stylesheet" type="text/css">
</head><body><section id="cover">
    <h1 id="title">lire ce qui n’a jamais été écrit</h1>
    <!-- <img src="images/Dd4aXZBU0AAwAmT.jpg" /> -->
    <!-- <img src="https://motherboard-images.vice.com/content-images/contentimage/26556/1444666824347969.jpg" /> -->
    <img src="https://motherboard-images.vice.com/content-images/contentimage/26556/1444666886307342.jpg" />
    <!-- <h2 id="author"></h2> -->
    <p id="booktitle">lire ce qui n’a jamais été écrit</p>
</section>

<section id="copyright">
    <!-- <p>Made with paged.js</p> -->
</section>

<section id="halftitle">
    <hgroup>
        <h1>Lire ce qui n’a jamais été écrit</h1>
        <!-- <h2>auteur</h2> -->
    </hgroup>
    <p class="printer">
        Esadse, mai 2019
    </p>
</section><section id="toc"><ul><li id="toc-introduction">
        <a href="#introduction">Introduction</a></li> <li class="chap"><a href="#acia">ACIA</a></li><li class="chap"><a href="#fake-news">Fake news</a></li><li class="chap"><a href="#frankenstein-native">Frankenstein Native</a></li><li class="chap"><a href="#le-chant-des-données">Le chant des données</a></li></ul></section><section id="introduction"><h1>Introduction</h1>
<p><em>Lire ce qui n’a jamais été écrit</em>, 
cette formule empruntée à Hugo Von Hofmannsthal, écrivain né à la fin du 19ème siècle en Autriche, est reprise par Emmanuel Alloa dans la traduction française de <em>Gramophone, Film, Typewriter</em> édité par les Presses du réel en 2018. Cet ouvrage de Friedrich Kittler paru initialement à Berlin en 1986 est maintenant un classique dans le champs des théories des média. 
Cette citation semble quelque peu anachronique lorsque que l'on l'utilise, c'est le cas ici, comme une référence à une certaine condition de la matière textuelle contemporaine.
Pourtant, lorsque Kittler évoque l'émergence des premières machines du traitement du langage et à toutes les transformations qu'elles engagent, nous sommes obligé de constater que ces tranformations n'ont jamais été aussi effectives qu'aujourd'hui.</p>
<p>Les appareillages médiatiques historiques, mécaniques, comme la machine à écrire annoncent les transformations du texte à venir par les technologies numériques : le statut de l'auteur, le texte écrit par les programmes informatiques autonomes qui peuplent le web, les logs, l'apprentissage machine, les commentaires modérés et triés automatiquement, la diffusion des informations. </p>
<p>Comment lire et surtout comprendre les contenus générés aujourd'hui ? Quelle sont les implications lorsque l'on écrit accompagné d'agents informatiques ?</p>
<p>C'est le point de départ des travaux présentés dans cette ouvrage (édition mise en page par un dispositif programmatique). Comme un début de réponse, ces travaux sont conçues et programmés par les étudian.te.s de deuxième années de l'École Supérieure d'Art et de Design de Saint-Étienne.</p>
<p>Jérémie Nuel</p></section><section id="acia" class="chapter" data-chapter="1"><h1>ACIA</h1>
<h2>Contexte</h2>
<p>Qu'est-ce-que l'identité ? 
Dans notre société dite moderne, il existe aujourd'hui d'innombrable moyens de fausser l'identité d’une personne, ou pire encore, de s'en créer une de toute pièce.
L'utilisation excessive de réseaux sociaux tels que Facebook, Twitter ou encore différents forums ont rendu facile et anodin tous types d’échanges entre n’importe qui. 
Mais comment être sûr que la personne avec qui l'on communique est bien celle que l'on souhaite, ou bien qu’elle existe dans la réalité, en dehors de son identité numérique ?
Au travers de cette installation nous nous sommes posé la question de l'identité, ce qu'elle engendre, et quels sont ses dérives possibles à l'ère du numérique et de l'hyper-connexion.
Le but de ce projet est de générer en continu une infinité d’identité numérique à l’aide de la génération procédurale. </p>
<p>Pour ce faire, l'utilisation de 2 Intelligence Artificielle (IA) est requise&nbsp;: une première Créatrice, qui va façonner un visage, statistiquement unique et n’ayant jamais existé, la seconde, le Juge, observe et analyse la création de la première pour en retirer un «&nbsp;compte-rendu&nbsp;».</p>
<p>Ces capacités de réflexions proches de l’humain qu’on retrouve chez ces IA découlent de leur éducation&nbsp;: l’apprentissage profond.</p>
<h2>Termes techniques</h2>
<h3>IA</h3>
<p>L' IA, consiste à mettre en œuvre un certain nombre de techniques visant à permettre aux machines d'imiter une forme d'intelligence réelle. La vision artificielle, celle de la machine, permet de déterminer précisément le contenu d'une image pour ensuite la classer automatiquement selon l'objet, la couleur, ou le visage repérer.</p>
<h3>Deep Learning</h3>
<p>Le Deep Learning ou apprentissage profond est un type d'intelligence artificielle dérivé du machine learning où la machine est capable d'apprendre par elle-même. 
Le Deep-Learning s'appuie sur un réseau de neurones artificiels, s'inspirant du cerveau humain. Ce réseau est composé de dizaines voire de centaines de « couches » de neurones, chacune recevant et interprétant les informations de la couche précédente. 
A chaque étape, les "mauvaises" réponses sont éliminées et renvoyées vers les niveaux en amont pour ajuster le modèle mathématique. Au fur et à mesure, le programme réorganise les informations en blocs plus complexes, il "apprend".</p>
<h2>Recolte de données</h2>
<h3>Thispersondoestnotexist</h3>
<p>La première Intelligence Artificielle se trouve sur le site "thispersondoesnotexist.com".
Ici, cette intelligence permet la création de visages de personnes de différentes personnes n'existant aucunement dans la réalité, de plus cette IA apprend en continu et créée ainsi des visages de plus en plus réalistes. 
Elle a été mise au point par Tero Karras, chercheur principal chez NVIDIA Research, qu'il a rejoint en 2009. 
Ses intérêts de recherche actuels tournent autour de l'apprentissage profond, des modèles génératifs et de la création de contenu numérique. </p>
<h3>Betaface</h3>
<p>Dans un second temps, nous utilisons «&nbsp;Betaface&nbsp;», une autre IA de reconnaissance faciale&nbsp;: ce système est une application logistique visant à automatiser la reconnaissance et l’analyse d’un visage. 
 Il est généralement utilisé à des fins de sécurité pour déverrouiller des ordinateurs/mobiles/console ou encore au contrôle des populations comme on a récemment pu le voir en Chine. 
 Crée par Oleksandr Kazakov, architecte logiciel expérimenté, entrepreneur, et fondateur d'une start-up de haute technologie, Betaface s'appuie sur différents éléments, tels que la forme du visage et ses attributs comme l'écartement des yeux et de la bouche, le nez, la pilosité. </p>
<p>Dans notre projet, nous utilisons la reconnaissance 2D, considérée comme la méthode "classique" de reconnaissance faciale, qui consiste à reconnaitre une personne à partir d'une photo. 
 Nous l’utilisons afin d’extraire trois de ses données, l’âge, le sexe, et les origines.</p>
<h2>Fonctionnement</h2>
<p>Flow-Chart </p>
<h2>Projet</h2>
<h3>Installation</h3>
<p>Photos de l'imprimante</p>
<h3>Identités</h3>
<p><img src="https://i.postimg.cc/CLtsGDv5/7-page-001-1.jpg" alt="" /></p>
<p><img src="https://i.postimg.cc/0ywdcQ3f/8-page-001.jpg" alt="" /></p>
<p><img src="https://i.postimg.cc/1z10TS1Z/9-page-001.jpg" alt="" /></p></section>
<section id="fake-news" class="chapter" data-chapter="2"><h1>Fake news</h1></section>
<section id="frankenstein-native" class="chapter" data-chapter="3"><h1>Frankenstein Native</h1>
<p>Maëva BORG</p>
<p>Mary Shelley</p>
<p>La Collection
Lire Ce qui n'a jamais été Ecrit </p>
<p>Comment penser l'Edition Numérique/digitale ? 
Quelle est la place du langage dans le mythe de Frankenstein ?
Quelle serait l'histoire du point de vue de la créature ? </p>
<p>Je trouvais intéressant de lier deux sujets réalisé cette année : «&nbsp;La Collection&nbsp;», et «&nbsp;Lire ce qui n’a jamais été écrit&nbsp;». 
Ces deux sujets amènent à réfléchir sur l'édition et de son contenu. 
La collection présente des livres de Science-fiction, et est introduite avec/par «&nbsp;Frankenstein ; Ou, le Prométhée Moderne&nbsp;» de Mary Shelley. </p>
<p>Dans le cas de "La Collection", L'edition est donc pensée physiquement, soit deux editions en une seule : Le texte original de Mary Shelley, et la partie générée.
La jaquette du livre permet de choisir si le lecteur veut lire le livre dans sa totalité, ou alors séparer les deux editions via les rabais de la jaquette.</p>
<p>Dans des critiques littéraires, la créature est considérée comme détentrice de la science divine.
Victor Frankenstein est lui, «&nbsp;créateur de l’humanité&nbsp;», le Prométhée moderne. 
Dans le mythe de Prométhée, l’homme crée par Prométhée, malgré ses paramètres encore trop faible pour se défendre correctement
face aux autres créatures terrestres. 
Dans le cas du roman de Mary Shelley,le schéma est agrémenté : Lorsque la créature est rejetée par l’Homme, 
elle se retourne contre son maître. 
Avant cela, elle souhaite s'intégrer dans le Monde Humain. Elle en vient à observer une famille où l'éducation d'une étrangère et la découverte des livres lui permettent d'apprendre à parler et à lire.
Cette partie m'intéressait car il y a un lien particulier au langage : La créature ne reçoit pas d'éducation donc n'a pas accès au langage. Il reagit de manière primitive et a donc un langage dit natif (langage de programmation) ou Primitif (langage parlé). 
Et pour s'intégrer, elle tente de parler le langage soutenu, parlé par les autres personnages, afin de pouvoir être à la hauteur de son créateur. </p>
<p>C'est ici qu'intervient "Lire ce qui n'a jamais été ecrit".</p>
<p>on peut supposer qu'Aujourd'hui avec le cas de l'Intelligence Artificielle, soumise au Machine Learning (Apprentissage Machine), peut être une transposition de la créature.
L'Intelligence Artificielle peut en effet apprendre à parler, ou s'entraîner à le faire, avec des paramètres qu'on lui impose.
Une fois le processus lancé, il y a deux types de pertes : regression loss et classification loss
(partie à revoir)
(caler westworld lien createur creature)</p>
<p>point historique du machine learning
La concrétisation de cette idée est principalement due à Alan Turing et à son concept de la « machine universelle » en 19362, qui est à la base des ordinateurs d'aujourd'hui. Il continuera à poser les bases de l'apprentissage automatique, avec son article sur « L'ordinateur et l'intelligence » en 19503, dans lequel il développe, entre autres, le test de Turing.</p>
<p>La première version ne contient pas de Machine Learning, mais un programme avec la Chaîne de Markov.
Les deux processus parlent de statistiques, mais celui de Markov fonctionne surtout par Probabilités.</p>
<p>Les processus de Markov portent le nom de leur inventeur, Andreï Markov. (1906)
"L'information utile pour la prédiction du futur est entièrement contenue dans l'état présent du processus et n'est pas dépendante des états antérieurs (le système n'a pas de « mémoire »)."
Les processus de Markov sont liés au mouvement brownien et à l'hypothèse ergodique, deux sujets de physique statistique qui ont été très importants au début du xxe siècle.</p>
<p>Dans le cas du texte littéraire, La chaine de Markov va prendre deux éléments, ici deux parties d'un même chapitre. 
Le processus est donc "conscient" du nombre de charactères qu'on lui donne, les analyse, puis mélange de manière aléatoire des éléments des deux textes, par probabilité.
Imaginons que les lettres de "Monster" apparaîssent 20 fois dans le même chapitre, il aura donc plus de chance d'apparaître dans le nouveau texte, généré par le processus. </p>
<p>Statistiques : machine learning /Markov : probabilités</p>
<p>Un programme informatique en code natif (ou langage machine) est composé d'instructions directement reconnues par un processeur.</p>
<p>En fait, la partie générée serait une proposition de ce que serait l'histoire vue par la créature, et non pas par les Humains. 
Poésie Concrete et Machine Learning sont alors liés. </p>
<p>En terme de visuels, Lire ce qui n'a jamais été ecrit avec FrankensteinNative va être une sorte d'AlterEgo de L'edition réalisée
pour "La Collection". Une sorte d'AntiLivre, terme emprunté à l'edition suisse Abrupt, qui pense le livre comme un PDF Do It Yourself. 
C'est-à-dire qu'on a le choix ou non de lire le texte dans son format Numérique, mais le fichier est également pensé pour être imprimé, puis relié. </p>
<p>Supports (techniques, et textes) utilisés :</p>
<ul>
<li>Project Gutenberg's Frankenstein, by Mary Wollstonecraft (Godwin) Shelley </li>
<li>Machine Learning</li>
<li>Chaîne de Markov </li>
</ul>
<p>Références&nbsp;:</p>
<ul>
<li>Allison Parish, «&nbsp;Frankenstein chatbot parade&nbsp;»&nbsp;: http://portfolio.decontextualize.com/</li>
<li>Collectif Algolittéraire  http://www.algolit.net/index.php/Main_Page</li>
<li>Frankenstein ; Ou, le Promethee moderne, de Mary Shelley. </li>
<li>Westworld, série HBO crée par Jonathan Nolan et Lisa Joy. </li>
<li>https://abrupt.ch/antilivre/</li>
</ul>
<p>Issues du projet FrankensteinNative x "Lire ce qui n'a jamais été écrit"&nbsp;:
"AntiLivre"
Editions Annexes
Affiches 
Bot Twitter </p></section>
<section id="le-chant-des-données" class="chapter" data-chapter="4"><h1>&nbsp;Le chant des données</h1>
<p>À l’ère de l’hégémonie du «digital», de nouveaux enjeux de pouvoir
apparaissent. En effet, alors que les gouvernements prennent
seulement conscience de l’importance de légiférer sur l’usage de la
donnée numérique, ils sont déjà devancés de plusieurs décennies
par certaines sociétés privées. Ces dernières ont su développer,
parallèlement à des moyens de stockage appropriés, des systèmes
de lecture pour traiter des masses de données en constant
accroissement, le big data.</p>
<p><img src="http://localhost:3000/images/nicolas/chant.jpg" alt="image" /></p>
<p>L’ordinateur, média composite par excellence, peut relayer des
données issues de tous types de média discrétisé,de comportement;
provenant de toutes sortes d’individu ou de groupe via internet.
Il est universellement utilisé, et en Europe, 80% de la population
pénètre régulièrement internet (www.blogdumoderateur.com).
Le comportement de l’internaute peut ainsi devenir objet d’analyse,
puis sujet d’influence.</p>
<p>Les publicités ciblées, l’adaptation du discours politique à un
échantillon donné (cf Cambridge Analytica),l’adaptation d’une création
audio-visuel à son audience (scénario de série Netflix), comptent parmi
tant d’autres exemples de l’impact du big data sur nos vies, de ce que
le numérique peut avoir de pervasif et d’ubiquitaire.</p>
<p>Si ces systèmes de lecture sont mis en place à des fins d’influence,
ils sont généralement cachés au public ou rendus difficilement
accessible, comme par exemple en plaçant les conditions et termes
d’utilisation dans une succession rapide d’étapes d‘installation.
L‘internaute n’a pas forcément conscience d’être monitoré, puis
manipulé par ce qu’il peut voir et faire à l’écran.</p>
<p>Pour mon projet, il m’a semblé intéressant de mettre en place
un programme permettant à l’utilisateur de pouvoir manipuler ces
données, à des fins ludiques, consistant en un système de lecture
musical. On sera invité à récupérer des données
provenant de comportements d’utilisateurs, des messages sur des
réseaux, pour les faire lire (de manière audible) par le
programme, grâce à un moteur de synthèse vocale. En début de se-
ssion, il pourra charger une production instrumentale sur laquelle
viendra «chanter» le programme, puis grâce à un contrôleur,
changer la vitesse d’élocution, la hauteur des notes ou encore jouer
des accords.</p>
<p>Ce programme aura comme but, en plus de s’amuser, de
rappeler de l’importance de faire attention à ce que l’on fait,
poste (etc…) sur internet; car ces données peuvent faire le jeu de
quelqu’un d’autre. Grâce à un soin porté sur la jouabilité du
programme et des effets sur le son, dirigé vers une IA de
synthèse vocale et des modèles de voix issus du deep learning,
l’ambition est de créer un nouvel outil de création musical.</p>
<h2>&nbsp;Descriptif</h2>
<p>Pour le moment, le programme fonctionne avec le moteur de
synthèse vocale de l’ordinateur (Espeak sous linux), qui produit
une voix pour le moins robotique (voire «programme à venir»).
Basé sur le web_scrapping, il invite à chercher des textes
destinnés à être lus par le moteur, ainsi qu’une production
instrumentale disponnible sur youtube. À l’issue de cette première
phase d’initialisation, deux fichiers sont créés, un texte
et une piste audio. Cette dernière sera analysée avant d’être
lue, afin d’en extraire le tempo.
Une vitesse de référence (jeu à la noire) est alors calculée pour
le moteur de synthèse vocale, alors calibré sur l’instrumentale.
Cette vitesse sera ensuite modulable de façon à pouvoir jouer
différents rythmes (ronde, croche…), des multiple du rythme
de référence.
Une fois cette phase d’initialisation achevée, l’instrumentale
est jouée automatiquement. C’est la phase de jeu et l’on
contrôle le moteur de synthèse au clavier.</p>
<h2>&nbsp;programme</h2>
<h3>&nbsp;vers une synthèse naturelle</h3>
<p>A terme, le programme sera entrainé avec une bibliothèque permettant
de faire du deep learning (Pytorch, TensorFlow…). Ainsi, il sera
possible de disposer pour le jeu d’un panel de modèles de voix,
issues d’un corpus (audio et texte). Il ne restera alors plus qu’à
choisir les voix que nousv voudrions jouer, que ce soit la notre ou
bien celle d’une diva, d’un personnage connu…
Le dévelloppement de ce domaine (text to speech) va bon train, et
il existe déjà quelques moteurs de synthèse basés sur des IA. Les
résultats sont étonnants de fidélité, et il devient ardu de demêler le
vrai du faux…</p>
<h3>vers une plus grande jouabilité</h3>
<p>Le deuxième axe de développement du programme sera sa jouabilité.
Plus de rythmes d’élocution, des effets implémentés au programme
(patch construits sous pure-data), la possibilté de réaliser des accords,
seront entre autres des améliorations apportées au programme pour le
rendre «jouable» comme l’on jouerai d’un autre instrument.
Paralellement, un controleur sera développé, qui permettra d’exploiter
au mieux toutes les fonctionnalités du programme.</p></section></body>